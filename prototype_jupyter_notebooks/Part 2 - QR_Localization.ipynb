{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pyzbar import pyzbar\n",
    "import math\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Newton Raphson Functions\n",
    "def DCreator(Guess, LenA, A, B, C, t):\n",
    "    c = 299792.458 # km/s\n",
    "    D = np.zeros((LenA, 4))\n",
    "    for i in range(LenA):\n",
    "        D[i] = [2*(Guess[0][0]-A[i]), 2*(Guess[1][0]-B[i]), 2*(Guess[2][0]-C[i]), 2*((c**2)*(t[i]-Guess[3][0]))]\n",
    "    return D\n",
    "\n",
    "def FCreator(Guess, LenA, A, B, C, t):\n",
    "    c = 299792.458\n",
    "    F = np.zeros((LenA, 1))\n",
    "    for i in range(LenA):\n",
    "        F[i] = (Guess[0][0]-A[i])**2 + (Guess[1][0]-B[i])**2 + (Guess[2][0]-C[i])**2 - (c*(t[i]-Guess[3][0]))**2\n",
    "    return F\n",
    "\n",
    "# Guess: 1 x #QR\n",
    "# A: 1 x #QR\n",
    "# B: 1 x #QR\n",
    "# C: 1 x #QR\n",
    "# t: 1 x #QR\n",
    "# LA: float\n",
    "def MVNewton(Guess, A, B, C, t, LA):\n",
    "    GuessTrans = np.array([[Guess[0]],[Guess[1]],[Guess[2]],[Guess[3]]])\n",
    "    c = 299792.458\n",
    "    \n",
    "    F = FCreator(GuessTrans, LA, A, B, C, t) \n",
    "    D = DCreator(GuessTrans, LA, A, B, C, t)\n",
    "    \n",
    "    for i in range(20):\n",
    "        V = np.linalg.lstsq(D, F*-1)\n",
    "        GuessTrans = GuessTrans + V[0]\n",
    "        F = FCreator(GuessTrans, LA, A, B, C, t)\n",
    "        D = DCreator(GuessTrans, LA, A, B, C, t)\n",
    "    \n",
    "    return GuessTrans\n",
    "\n",
    "# G_ = [0,0,0,0] # initial guess\n",
    "# A_ = [1,2,3] # x-coordinates\n",
    "# B_ = [1,2,3] # y-coordinates\n",
    "# C_ = [0,0,0] # z-coordinates\n",
    "# T_ = [1,2,3] # time-offset\n",
    "\n",
    "# G_ = [0,0,670,0] # initial guess\n",
    "# A_ = [15600,18760,17610,19170] # x-coordinates\n",
    "# B_ = [7540,2750,14630,610] # y-coordinates\n",
    "# C_ = [20140,18610,13480,18390] # z-coordinates\n",
    "# T_ = [0.07074,0.07220,0.07690,0.07242] # time-offset\n",
    "\n",
    "# print(MVNewton(G_, A_, B_, C_, T_, len(A_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30) # depth stream\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30) # color stream\n",
    "align = rs.align(rs.stream.color) # align both streams to same pov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable visualizer and filters for later use\n",
    "colorizer = rs.colorizer()\n",
    "spatial = rs.spatial_filter()\n",
    "spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "spatial.set_option(rs.option.filter_smooth_alpha, 1)\n",
    "spatial.set_option(rs.option.filter_smooth_delta, 50)\n",
    "spatial.set_option(rs.option.holes_fill, 3)\n",
    "hole_filling = rs.hole_filling_filter()\n",
    "depth_to_disparity = rs.disparity_transform(True)\n",
    "disparity_to_depth = rs.disparity_transform(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\neelo\\anaconda3\\envs\\opencv-env\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "# Start streaming\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        frames = align.process(frames)\n",
    "        \n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # filter depth stream: depth2disparity -> spatial -> disparity2depth -> hole_filling\n",
    "        depth_frame = depth_to_disparity.process(depth_frame)\n",
    "        depth_frame = spatial.process(depth_frame)\n",
    "        depth_frame = disparity_to_depth.process(depth_frame)\n",
    "        depth_frame = hole_filling.process(depth_frame)\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        \n",
    "        # detect and decode barcodes\n",
    "        object_depth = np.asanyarray(depth_frame.get_data())\n",
    "        barcode_poses = []\n",
    "        barcodes = pyzbar.decode(color_image)\n",
    "        \n",
    "        X_ = []\n",
    "        Y_ = []\n",
    "        Z_ = []\n",
    "        D_ = []\n",
    "        T_ = []\n",
    "        \n",
    "        for barcode in barcodes:\n",
    "            (x, y, w, h) = barcode.rect\n",
    "            cv2.rectangle(color_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            cv2.rectangle(depth_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            barcodeData = barcode.data.decode(\"utf-8\")\n",
    "            barcodeType = barcode.type\n",
    "            \n",
    "            curr = copy.deepcopy(object_depth)\n",
    "            curr = curr[math.floor(((x)+(x+w))/2-1):math.ceil(((x)+(x+w))/2+1),math.floor(((y)+(y+h))/2-1):math.ceil(((y)+(y+h))/2+1)].astype(float)\n",
    "            depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "            curr = curr * depth_scale\n",
    "            dist,_,_,_ = cv2.mean(curr)\n",
    "            barcode_poses.append((barcodeData, dist))\n",
    " \n",
    "            # draw the barcode data and barcode type on the image\n",
    "            text = \"{} ({})\".format(barcodeData, dist)\n",
    "            cv2.putText(color_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            \n",
    "            # store poses of codes\n",
    "            curr_pose = re.split(',|\\(|\\)',barcodeData)\n",
    "            X_.append(float(curr_pose[1]))\n",
    "            Y_.append(float(curr_pose[2]))\n",
    "            Z_.append(float(curr_pose[3]))\n",
    "            D_.append(dist)\n",
    "            T_.append((dist/(10**3))/299792.458)\n",
    "        \n",
    "        if barcodes:\n",
    "            curr_cam_pos = MVNewton([0,0,0,0], X_, Y_, Z_, T_, len(barcodes))\n",
    "            \n",
    "            text_pos_x = 'X: ' + str(curr_cam_pos[0][0])\n",
    "            text_pos_y = 'Y: ' + str(curr_cam_pos[1][0])\n",
    "            text_pos_z = 'Z: ' + str(curr_cam_pos[2][0])\n",
    "            text_pos_error = 'Error: ' + str(curr_cam_pos[3][0])\n",
    "            \n",
    "            cv2.putText(depth_image, text_pos_x, (20, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(depth_image, text_pos_y, (20, 420), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(depth_image, text_pos_z, (20, 440), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(depth_image, text_pos_error, (20, 460), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "           \n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_image))\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
