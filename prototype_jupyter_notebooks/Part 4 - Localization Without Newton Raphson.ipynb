{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pyzbar import pyzbar\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rotation_estimator:\n",
    "    def __init__(self):\n",
    "        self.theta = [0.0,0.0,0.0]\n",
    "        self.alpha = 0.98\n",
    "        self.first = True\n",
    "        self.last_ts_gyro = 0.0\n",
    "    \n",
    "    # Function to calculate the change in angle of motion based on data from gyro\n",
    "    # gyro_data - list of 3 elems\n",
    "    # ts - float arrival time of curr gyro frame\n",
    "    def process_gyro(self, gyro_data, ts):\n",
    "        if self.first:\n",
    "            self.last_ts_gyro = ts\n",
    "            return\n",
    "        \n",
    "        gyro_angle = [gyro_data.x,gyro_data.y,gyro_data.z]\n",
    "        \n",
    "        dt_gyro = (ts-self.last_ts_gyro)/1000.0\n",
    "        self.last_ts_gyro = ts\n",
    "        \n",
    "        gyro_angle = [gyro_angle[0]*dt_gyro,gyro_angle[1]*dt_gyro,gyro_angle[2]*dt_gyro]\n",
    "        \n",
    "        self.theta = [self.theta[0]-gyro_angle[2],self.theta[1]-gyro_angle[1],self.theta[2]+gyro_angle[0]]\n",
    "    \n",
    "    # Function to calculate the change in angle of motion based on data from accelerometer\n",
    "    # accel_data - list of 3 elems\n",
    "    def process_accel(self, accel_data):\n",
    "        accel_angle = [0.0,0.0,0.0]\n",
    "        accel_angle[2] = np.arctan2(accel_data.y,accel_data.z)\n",
    "        accel_angle[0] = np.arctan2(accel_data.x, np.sqrt(accel_data.y**2+accel_data.z**2))\n",
    "        \n",
    "        if self.first:\n",
    "            self.first = False\n",
    "            self.theta = accel_angle\n",
    "            self.theta[1] = np.pi/2\n",
    "        else:\n",
    "            self.theta[0] = self.theta[0]*self.alpha + accel_angle[0]*(1-self.alpha)\n",
    "            self.theta[2] = self.theta[2]*self.alpha + accel_angle[2]*(1-self.alpha)\n",
    "        \n",
    "    def get_theta(self):\n",
    "        theta_out = [0.0,0.0,0.0]\n",
    "        theta_out = [self.theta[0]*180/np.pi, self.theta[1]*180/np.pi, (self.theta[2]-np.pi/2)*180/np.pi]\n",
    "        return theta_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30) # depth stream\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30) # color stream\n",
    "config.enable_stream(rs.stream.gyro) # gyro stream\n",
    "config.enable_stream(rs.stream.accel) # accelerometer stream\n",
    "align = rs.align(rs.stream.color) # align both streams to same pov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable visualizer and filters for later use\n",
    "colorizer = rs.colorizer()\n",
    "spatial = rs.spatial_filter()\n",
    "spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "spatial.set_option(rs.option.filter_smooth_alpha, 1)\n",
    "spatial.set_option(rs.option.filter_smooth_delta, 50)\n",
    "spatial.set_option(rs.option.holes_fill, 3)\n",
    "hole_filling = rs.hole_filling_filter()\n",
    "depth_to_disparity = rs.disparity_transform(True)\n",
    "disparity_to_depth = rs.disparity_transform(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start streaming\n",
    "algo = rotation_estimator()\n",
    "profile = pipeline.start(config)\n",
    "first_run = True\n",
    "\n",
    "try:\n",
    "    while True:        \n",
    "        if first_run:\n",
    "            try:\n",
    "                frames = pipeline.wait_for_frames()\n",
    "                \n",
    "                accel_frame = frames.first_or_default(rs.stream.accel)\n",
    "                if accel_frame:\n",
    "                    accel_data = accel_frame.as_motion_frame().get_motion_data()\n",
    "                \n",
    "                gyro_frame = frames.first_or_default(rs.stream.gyro)\n",
    "                if gyro_frame:\n",
    "                    gyro_data = gyro_frame.as_motion_frame().get_motion_data()\n",
    "                    gyro_ts = gyro_frame.as_motion_frame().get_timestamp()\n",
    "            \n",
    "                if not accel_frame or not gyro_frame:\n",
    "#                     print(\"FIRST NOT FOUND\")\n",
    "                    break\n",
    "                    \n",
    "                algo.process_gyro(gyro_data, gyro_ts)\n",
    "                algo.process_accel(accel_data)\n",
    "                first_run = False\n",
    "#                 print(\"FIRST PROCESSED\")\n",
    "                continue\n",
    "\n",
    "            except:\n",
    "#                 print(\"EXCEPTION\")\n",
    "                break\n",
    "        \n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        frames = align.process(frames)\n",
    "        \n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        accel_frame = frames.first_or_default(rs.stream.accel)\n",
    "        if accel_frame:\n",
    "            accel_data = accel_frame.as_motion_frame().get_motion_data()\n",
    "\n",
    "        gyro_frame = frames.first_or_default(rs.stream.gyro)\n",
    "        if gyro_frame:\n",
    "            gyro_data = gyro_frame.as_motion_frame().get_motion_data()\n",
    "            gyro_ts = gyro_frame.as_motion_frame().get_timestamp()\n",
    "\n",
    "        if not accel_frame or not gyro_frame:\n",
    "#             print(\"LOOPED ACCEL/GYRO FRAME NOT FOUND\")\n",
    "            continue\n",
    "\n",
    "        algo.process_gyro(gyro_data, gyro_ts)\n",
    "        algo.process_accel(accel_data)\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "#             print(\"LOOPED DEPTH/COLOR FRAME NOT FOUND\")\n",
    "            continue\n",
    "\n",
    "        # filter depth stream: depth2disparity -> spatial -> disparity2depth -> hole_filling\n",
    "        depth_frame = depth_to_disparity.process(depth_frame)\n",
    "        depth_frame = spatial.process(depth_frame)\n",
    "        depth_frame = disparity_to_depth.process(depth_frame)\n",
    "        depth_frame = hole_filling.process(depth_frame)\n",
    "\n",
    "        # get intrinsics\n",
    "        depth_intrin = depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "        color_intrin = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        \n",
    "        # detect and decode barcodes\n",
    "        object_depth = np.asanyarray(depth_frame.get_data())\n",
    "        barcode_poses = []\n",
    "        barcodes = pyzbar.decode(color_image)\n",
    "            \n",
    "        bar_x = []\n",
    "        bar_y = []\n",
    "        robo_x = []\n",
    "        robo_y = []\n",
    "        \n",
    "        for barcode in barcodes:\n",
    "            (x, y, w, h) = barcode.rect\n",
    "            cv2.rectangle(color_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            cv2.rectangle(depth_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            barcodeData = barcode.data.decode(\"utf-8\")\n",
    "            barcodeType = barcode.type\n",
    "            \n",
    "            curr = copy.deepcopy(object_depth)\n",
    "            curr = curr[math.floor(((x)+(x+w))/2-1):math.ceil(((x)+(x+w))/2+1),math.floor(((y)+(y+h))/2-1):math.ceil(((y)+(y+h))/2+1)].astype(float)\n",
    "            depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "            curr = curr * depth_scale\n",
    "            dist,_,_,_ = cv2.mean(curr)\n",
    "            barcode_poses.append((barcodeData, dist))\n",
    " \n",
    "            # draw the barcode data and barcode type on the image\n",
    "            text = \"{} ({})\".format(barcodeData, dist)\n",
    "            cv2.putText(color_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            \n",
    "            # store poses of codes\n",
    "            curr_pose = re.split(',|\\(|\\)',barcodeData)\n",
    "            bar_x.append(float(curr_pose[1]))\n",
    "            bar_y.append(float(curr_pose[2]))\n",
    "            \n",
    "            # Get 3d point of object detected\n",
    "            relative_depth_point = rs.rs2_deproject_pixel_to_point(depth_intrin, [int((x+(x+w))/2), int((y+(y+h))/2)], dist)\n",
    "#             print(\"\\Relative Point: \\nX \",relative_depth_point[0],\"\\nY \",relative_depth_point[1],\"\\nZ \",relative_depth_point[2])\n",
    "            \n",
    "            \n",
    "            # Get world position of cam according to this barcode\n",
    "            curr_cam_theta = algo.get_theta()[1]\n",
    "#             print(\"Cam Theta: \\n\",curr_cam_theta)\n",
    "            curr_cam_phi = np.arctan2(relative_depth_point[2],relative_depth_point[0])*180/np.pi\n",
    "#             print(\"Cam Phi: \\n\",curr_cam_phi)\n",
    "            curr_cam_alpha = 90 - curr_cam_theta + curr_cam_phi\n",
    "#             print(\"Cam Alpha: \\n\",curr_cam_alpha)\n",
    "            curr_cam_delta_x = dist*np.cos(np.radians(curr_cam_alpha))\n",
    "#             print(\"Cam delta_x: \\n\",curr_cam_delta_x)\n",
    "            curr_cam_delta_y = dist*np.sin(np.radians(curr_cam_alpha))\n",
    "#             print(\"Cam delta_y: \\n\",curr_cam_delta_y)             \n",
    "#             print(\"\\nBarcode Pose: \\nX \",curr_pose[1],\"\\nY \",curr_pose[2])\n",
    "            robo_x.append(float(curr_pose[1])-float(curr_cam_delta_x))\n",
    "            robo_y.append(float(curr_pose[2])-float(curr_cam_delta_y))\n",
    "\n",
    "        if barcodes:\n",
    "            curr_cam_pos = [np.average(robo_x), np.average(robo_y)]\n",
    "            \n",
    "            text_pos_x = 'X: ' + str(curr_cam_pos[0])\n",
    "            text_pos_y = 'Y: ' + str(curr_cam_pos[1])\n",
    "            \n",
    "            cv2.putText(depth_image, text_pos_x, (20, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(depth_image, text_pos_y, (20, 420), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "        # Stack both images horizontally\n",
    "        images = np.hstack((color_image, depth_image))\n",
    "\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
